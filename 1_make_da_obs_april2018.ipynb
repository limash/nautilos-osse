{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ROMS I4DVar observation file from a ROMS output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import cftime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments:\n",
    "    start_time: str = '2018-04-01'\n",
    "    end_time: str = '2018-04-07'\n",
    "    input_grid_file: str = '/cluster/projects/nn9490k/ROHO800/Grid/ROHO800_grid_fix5.nc'\n",
    "    input_data_files: tuple = (\n",
    "        '/cluster/projects/nn9297k/ROHO160+/OutputData/s_layers_25/1_dec2017-dec2018/roho160_his_0011.nc',\n",
    "        '/cluster/projects/nn9297k/ROHO160+/OutputData/s_layers_25/1_dec2017-dec2018/roho160_his_0012.nc',\n",
    "    )\n",
    "    wc13_obs_file: str = '/cluster/home/shmiak/src/roms-applications/WC13/Data/wc13_obs.nc'\n",
    "    output_obs_file: str = '/cluster/projects/nn9297k/shmiak/roho800_data/input_data/roho800_obs_sst_roho160_2018-04-01_to_2018-04-07.nc'\n",
    "    stations: str = '/cluster/projects/nn9490k/ROHO800/STORAGE/ROHO800_hindcast_2007_2019_v2bn/concatenated/stations/roho800_v2bn_sta.nc'\n",
    "\n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate (regrid) temperature from 160 m to 800 m (checkup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary nc files to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = slice(args.start_time, args.end_time)\n",
    "ds_data = xr.open_mfdataset(list(args.input_data_files)).sel(ocean_time=time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_grid = xr.open_dataset(args.input_grid_file)\n",
    "wc13_obs = xr.open_dataset(args.wc13_obs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare variables and resample from 160 to 800 meters domain.\n",
    "Description of xesmf is unclear for me, so renaming is to follow the examples\n",
    "at `https://xesmf.readthedocs.io/en/latest/notebooks/Curvilinear_grid.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = ds_grid.rename({\"lon_rho\": \"lon\", \"lat_rho\": \"lat\"})\n",
    "ds = ds_data.rename({\"lon_rho\": \"lon\", \"lat_rho\": \"lat\"})\n",
    "da_temp = ds['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(ds, ds_out, \"bilinear\", unmapped_to_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_out = regridder(da_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_temp.isel(ocean_time=-1, s_rho=-1).plot(figsize=(14, 7))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_out.isel(ocean_time=-1, s_rho=-1).plot(figsize=(14, 7))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sst = da_out.isel(s_rho=-1) / ds_grid.mask_rho  # type: ignore ; exclude values outside the sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sst = da_sst.rename({\"ocean_time\": \"time\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the coordinates of the observation stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_roho800_st = xr.open_dataset(args.stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons, lats = np.zeros(ds_roho800_st.station.shape), np.zeros(ds_roho800_st.station.shape)\n",
    "for i, station in enumerate(ds_roho800_st.station):\n",
    "    lons[i] = station.lon_rho.values\n",
    "    lats[i] = station.lat_rho.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['VT53', 'VT70', 'VT74', 'VT69']\n",
    "n_point = [1, 3, 4, 13]\n",
    "p = ds_grid.mask_rho.plot(\n",
    "    x=\"lon_rho\", y=\"lat_rho\", figsize=(14, 7), cmap='GnBu'\n",
    "    )\n",
    "p.axes.scatter(x=lons[n_point], y=lats[n_point], color='red')\n",
    "for i, label in enumerate(labels):\n",
    "    p.axes.annotate(label, (lons[n_point][i], lats[n_point][i]), color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate 160 m output to data assimilation stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stations_out = xr.Dataset(\n",
    "    {\n",
    "        \"lat\": ([\"lat\"], lats[n_point], {\"units\": \"degrees_north\"}),\n",
    "        \"lon\": ([\"lon\"], lons[n_point], {\"units\": \"degrees_east\"}),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(ds, ds_stations_out, \"bilinear\", unmapped_to_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_stations_temp = regridder(da_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_stations_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data arrays for the ROMS data assimilation observation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_stations_temp.isel(ocean_time=-1, s_rho=-1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.isfinite(da_sst.isel(time=0).values)  # mask of grid points without data\n",
    "points_per_time = mask.flatten()[mask.flatten()==True].shape[0]\n",
    "time_points = da_sst.time.shape[0]\n",
    "print(f\"The number of points per time: {points_per_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattens from the last dimenstion: (x, y, z) so z -> y -> x\n",
    "np_sst = da_sst.values.flatten(order='C')\n",
    "np_sst = np_sst[np.isfinite(np_sst)]\n",
    "np_sst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_type = np.full_like(np_sst, 6, dtype=np.int32)\n",
    "np_type.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_provenance = np.full_like(np_sst, 1, dtype=np.int32)\n",
    "np_provenance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sst.time.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change time of the first obs to correspond to the init conditions file\n",
    "# roms doesn't read `days since ...` from this file, it uses this date from \n",
    "# another file\n",
    "# time_cftime = cftime.datetime(2018, 9, 24)\n",
    "# da_sst.time.data[0] = time_cftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sst.time.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np datetime64 to python datetime to cftime num\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "# da_sst.time.data.dtype\n",
    "# np.datetime64('1970-01-01T00:00:00', \"ns\").dtype\n",
    "# timestamp = ((da_sst.time.data - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's'))\n",
    "# dt_sst = datetime.utcfromtimestamp(int(timestamp))\n",
    "# cftime.date2num(dt_sst, \"days since 2007-01-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_time = np.repeat(da_sst.time.values[..., np.newaxis], points_per_time, axis=1).flatten()\n",
    "np_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "ax.plot(np_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_depth\n",
    "If positive, should be a ROMS grid level, for example, 25 is a top layer if there are 25 layers\n",
    "If negative, meters, not tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_depth = np.full_like(np_sst, 25)\n",
    "np_depth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_Xgrid and obs_Ygrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx, y_idx = np.where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_xgrid = np.tile(x_idx.astype(dtype=np.float64) + 1, time_points)\n",
    "np_ygrid = np.tile(y_idx.astype(dtype=np.float64) + 1, time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "ax.plot(np_xgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_xgrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ygrid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_Zgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_zgrid = np.full_like(np_sst, 0)\n",
    "np_zgrid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### obs_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_sst_std = da_sst_std.values.flatten(order='C')\n",
    "# np_sst_std = np_sst_std[~np.isnan(np_sst_std)]\n",
    "# np_sst_var = np_sst_std ** 2\n",
    "# np_error = np.repeat(np_sst_var, time_points)\n",
    "np_error = np.full_like(np_sst, 0.4**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_error.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### survey_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_survey_time = da_sst.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_survey_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np_nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_nobs = np.repeat(points_per_time, time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_nobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np_lon and np_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lon = np.tile(ds_grid.lon_rho.values.flatten()[mask.flatten()==True], time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lat = np.tile(ds_grid.lat_rho.values.flatten()[mask.flatten()==True], time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    {\n",
    "        \"spherical\": 1,\n",
    "        \"Nobs\": (\"survey\", np_nobs),\n",
    "        \"survey_time\": (\"survey\", np_survey_time),\n",
    "        \"obs_variance\": (\"state_variable\", wc13_obs.obs_variance.data),\n",
    "        \"obs_value\": (\"datum\", np_sst),\n",
    "        \"obs_type\": (\"datum\", np_type),\n",
    "        \"obs_provenance\": (\"datum\", np_provenance),\n",
    "        \"obs_time\": (\"datum\", np_time),\n",
    "        \"obs_depth\": (\"datum\", np_depth),\n",
    "        \"obs_Xgrid\": (\"datum\", np_xgrid),\n",
    "        \"obs_Ygrid\": (\"datum\", np_ygrid),\n",
    "        \"obs_Zgrid\": (\"datum\", np_zgrid),\n",
    "        \"obs_error\": (\"datum\", np_error),\n",
    "        \"obs_lon\": (\"datum\", np_lon),\n",
    "        \"obs_lat\": (\"datum\", np_lat),\n",
    "    },\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(args.output_obs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
