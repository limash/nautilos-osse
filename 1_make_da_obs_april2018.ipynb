{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ROMS I4DVar observation file from a ROMS output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import cftime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no nc stations file for this time period, get from the next period for coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments:\n",
    "    start_time: str = '2018-04-01'\n",
    "    end_time: str = '2018-04-07'\n",
    "    input_grid_file: str = '/cluster/projects/nn9490k/ROHO800/Grid/ROHO800_grid_fix5.nc'\n",
    "    input_data_files: tuple = (\n",
    "        '/cluster/projects/nn9297k/ROHO160+/OutputData/s_layers_25/1_dec2017-dec2018/roho160_his_0011.nc',\n",
    "        '/cluster/projects/nn9297k/ROHO160+/OutputData/s_layers_25/1_dec2017-dec2018/roho160_his_0012.nc',\n",
    "    )\n",
    "    stations: str = '/cluster/projects/nn9297k/ROHO160+/OutputData/s_layers_25/2_dec2018-sep2019/roho160_sta.nc'\n",
    "    wc13_obs_file: str = '/cluster/home/shmiak/src/roms-applications/WC13/Data/wc13_obs.nc'\n",
    "    output_obs_file: str = '/cluster/projects/nn9297k/shmiak/roho800_data/input_data/roho800_obs_sst_roho160_2018-04-01_to_2018-04-07.nc'\n",
    "\n",
    "args = Arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary nc files to datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = slice(args.start_time, args.end_time)\n",
    "ds_data = xr.open_mfdataset(list(args.input_data_files)).sel(ocean_time=time_slice)\n",
    "ds_stations = xr.open_dataset(args.stations).sel(ocean_time=time_slice)\n",
    "ds_grid = xr.open_dataset(args.input_grid_file)\n",
    "ds_wc13_obs = xr.open_dataset(args.wc13_obs_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate (regrid) temperature from 160 m to 800 m (checkup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare variables and resample from 160 to 800 meters domain.\n",
    "Description of xesmf is unclear for me, so renaming is to follow the examples\n",
    "at `https://xesmf.readthedocs.io/en/latest/notebooks/Curvilinear_grid.html`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_grid = ds_grid.rename({\"lon_rho\": \"lon\", \"lat_rho\": \"lat\"})\n",
    "ds_data = ds_data.rename({\"lon_rho\": \"lon\", \"lat_rho\": \"lat\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(ds_data, ds_grid, \"bilinear\", unmapped_to_nan=True)\n",
    "da_sst = regridder(ds_data['temp']).isel(s_rho=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sst = da_sst / ds_grid.mask_rho  # type: ignore ; exclude values outside the sea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data['temp'].isel(ocean_time=-1, s_rho=-1).plot(figsize=(14, 7))  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sst.isel(ocean_time=-1).plot(figsize=(14, 7))  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the coordinates of the observation stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_lons, st_lats = np.zeros(ds_stations.station.shape), np.zeros(ds_stations.station.shape)\n",
    "for i, station in enumerate(ds_stations.station):\n",
    "    st_lons[i] = station.lon_rho.values\n",
    "    st_lats[i] = station.lat_rho.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_labels = ['VT53', 'VT70', 'VT74', 'VT69']\n",
    "st_n_point = [1, 3, 4, 9]\n",
    "p = ds_grid.mask_rho.plot(\n",
    "    x=\"lon\", y=\"lat\", figsize=(14, 7), cmap='GnBu'\n",
    "    )\n",
    "p.axes.scatter(x=st_lons[st_n_point], y=st_lats[st_n_point], color='red')\n",
    "for i, label in enumerate(st_labels):\n",
    "    p.axes.annotate(label, (st_lons[st_n_point][i], st_lats[st_n_point][i]), color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate 160 m output to the data assimilation stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_st_coords = xr.Dataset(\n",
    "    {\n",
    "        \"lat\": ([\"lat\"], st_lats[st_n_point], {\"units\": \"degrees_north\"}),\n",
    "        \"lon\": ([\"lon\"], st_lons[st_n_point], {\"units\": \"degrees_east\"}),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regridder = xe.Regridder(ds_data, ds_st_coords, \"bilinear\", unmapped_to_nan=True)\n",
    "da_stations_temp = regridder(ds_data['temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xesmf interpolates to the grid that is a combination of station coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_stations_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the diagonal elements along the lat and lon dimensions, these are stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_stations = da_stations_temp.values.diagonal(axis1=2, axis2=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_stations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_stations[0, 3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_stations_temp.isel(ocean_time=0, s_rho=3).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data arrays for the ROMS data assimilation observation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_per_time = len(st_n_point) * da_stations_temp.s_rho.shape[0]\n",
    "time_points = da_stations_temp.ocean_time.shape[0]\n",
    "print(f\"There are {points_per_time} observations per time and {time_points} time points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_stations[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_stations[0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_stations.flatten()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattens from the last dimenstion: (x, y, z) so z -> y -> x\n",
    "na_st_temp = na_stations.flatten()\n",
    "na_st_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_st_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order of values: 'VT53', 'VT70', 'VT74', 'VT69' from the bottom upwards, from the first time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_type = np.full_like(na_st_temp, 6, dtype=np.int32)\n",
    "na_type.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_provenance = np.full_like(na_st_temp, 1, dtype=np.int32)\n",
    "na_provenance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_time = np.repeat(da_stations_temp.ocean_time.values[..., np.newaxis], points_per_time, axis=1).flatten()\n",
    "na_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.plot(na_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_depth\n",
    "\n",
    "If positive, should be a ROMS grid level, for example, 25 is a top layer if there are 25 layers\n",
    "If negative, meters, not tested\n",
    "\n",
    "Here should be like 1 1 1 1 2 2 2 2... 25 25 25 25 1 1 1 1 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_time_step = np.repeat(np.arange(1, 26, 1)[..., np.newaxis], len(st_n_point), axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_depth = np.tile(depth_time_step, time_points)\n",
    "na_depth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_Xgrid and obs_Ygrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx, y_idx = np.where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_xgrid = np.tile(x_idx.astype(dtype=np.float64) + 1, time_points)\n",
    "np_ygrid = np.tile(y_idx.astype(dtype=np.float64) + 1, time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 7))\n",
    "ax.plot(np_xgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_xgrid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ygrid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_Zgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_zgrid = np.full_like(np_sst, 0)\n",
    "np_zgrid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obs_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_sst_std = da_sst_std.values.flatten(order='C')\n",
    "# np_sst_std = np_sst_std[~np.isnan(np_sst_std)]\n",
    "# np_sst_var = np_sst_std ** 2\n",
    "# np_error = np.repeat(np_sst_var, time_points)\n",
    "np_error = np.full_like(np_sst, 0.4**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_error.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "survey_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_survey_time = da_sst.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_survey_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np_nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_nobs = np.repeat(points_per_time, time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_nobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np_lon and np_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lon = np.tile(ds_grid.lon_rho.values.flatten()[mask.flatten()==True], time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lat = np.tile(ds_grid.lat_rho.values.flatten()[mask.flatten()==True], time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_lat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.Dataset(\n",
    "    {\n",
    "        \"spherical\": 1,\n",
    "        \"Nobs\": (\"survey\", np_nobs),\n",
    "        \"survey_time\": (\"survey\", np_survey_time),\n",
    "        \"obs_variance\": (\"state_variable\", wc13_obs.obs_variance.data),\n",
    "        \"obs_value\": (\"datum\", np_sst),\n",
    "        \"obs_type\": (\"datum\", np_type),\n",
    "        \"obs_provenance\": (\"datum\", np_provenance),\n",
    "        \"obs_time\": (\"datum\", np_time),\n",
    "        \"obs_depth\": (\"datum\", np_depth),\n",
    "        \"obs_Xgrid\": (\"datum\", np_xgrid),\n",
    "        \"obs_Ygrid\": (\"datum\", np_ygrid),\n",
    "        \"obs_Zgrid\": (\"datum\", np_zgrid),\n",
    "        \"obs_error\": (\"datum\", np_error),\n",
    "        \"obs_lon\": (\"datum\", np_lon),\n",
    "        \"obs_lat\": (\"datum\", np_lat),\n",
    "    },\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(args.output_obs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
